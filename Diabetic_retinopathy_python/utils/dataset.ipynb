{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset.ipynb","provenance":[],"authorship_tag":"ABX9TyPp/UY+zN3qa5gsliohF5Sj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"XIWGEMNU7kpe","colab_type":"code","colab":{}},"source":["import math\n","import torch\n","import random\n","import numpy as np\n","from PIL import Image\n","from torch.utils.data import Dataset\n","from torchvision.transforms import functional as TF\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, imgs, masks, data_augmentation=False):\n","        self.imgs = imgs\n","        self.masks = masks\n","        self.data_augmentation = data_augmentation\n","        self.p = 0.5\n","\n","    def __len__(self):\n","        return self.imgs.shape[0]\n","\n","    @staticmethod\n","    def get_params(img, output_size):\n","        \"\"\"Get parameters for ``crop`` for a random crop.\n","        Args:\n","            img (PIL Image): Image to be cropped.\n","            output_size (tuple): Expected output size of the crop.\n","        Returns:\n","            tuple: params (i, j, h, w) to be passed to ``crop`` for random crop.\n","        \"\"\"\n","        w, h = img.size\n","        th, tw = output_size\n","        if w == tw and h == th:\n","            return 0, 0, h, w\n","\n","        i = random.randint(0, h - th)\n","        j = random.randint(0, w - tw)\n","        return i, j, th, tw\n","\n","    def __getitem__(self, idx):\n","        img = np.reshape(self.imgs[idx], (self.imgs[idx].shape[1], self.imgs[idx].shape[2]))\n","        mask = np.reshape(self.masks[idx], (self.masks[idx].shape[1], self.masks[idx].shape[2]))\n","        h, w = img.shape[0], img.shape[1]\n","        img = Image.fromarray(img)\n","        mask = Image.fromarray(mask)\n","\n","        if self.data_augmentation is True and random.random() < 0.6:\n","            # 随机水平翻转\n","            if random.random() > self.p:\n","                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n","                mask = mask.transpose(Image.FLIP_LEFT_RIGHT)\n","            # 随机垂直翻转\n","            if random.random() > self.p:\n","                img = img.transpose(Image.FLIP_TOP_BOTTOM)\n","                mask = mask.transpose(Image.FLIP_TOP_BOTTOM)\n","            # 逆时针90度\n","            if random.random() > self.p:\n","                img = img.transpose(Image.ROTATE_90)\n","                mask = mask.transpose(Image.ROTATE_90)\n","            # 逆时针180度\n","            if random.random() > self.p:\n","                img = img.transpose(Image.ROTATE_180)\n","                mask = mask.transpose(Image.ROTATE_180)\n","            # 逆时针270度\n","            if random.random() > self.p:\n","                img = img.transpose(Image.ROTATE_270)\n","                mask = mask.transpose(Image.ROTATE_270)\n","            # 随机裁剪\n","            img = TF.pad(img, int(math.ceil(h * 1 / 8)))\n","            mask = TF.pad(mask, int(math.ceil(h * 1 / 8)))\n","            i, j, h, w = self.get_params(img, (h, w))\n","            img = img.crop((j, i, j + w, i + h))\n","            mask = mask.crop((j, i, j + w, i + h))\n","\n","        return TF.to_tensor(img), torch.from_numpy(np.array(mask)).long()\n","\n","\n","class TestDataset(Dataset):\n","    def __init__(self, patches_imgs):\n","        self.imgs = patches_imgs\n","\n","    def __len__(self):\n","        return self.imgs.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.from_numpy(self.imgs[idx, ...]).float()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YbJ3ohux7627","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}